## Data Modeling with Postgres

### Purpose of Database:
This project involved creating a database for the startup company 'Sparkify'. The purpose of the database was to analyze the data Sparkify collected on songs and user activity through their new music streaming app. Sparkify's main interests were in understanding what songs their users are listening to. The creation of this database will allow Sparkify to analyze their data in a much more efficient format. They will be able to better identify their targets audiences to reach their analytical goals.

#### Datasets:
Sparkify's data they would like to analyze was contained in a directory of JSON logs which created the need for the database. The directory of JSON logs included the user activity data from the streaming app as well as metadata on the songs.

* The song dataset is a subset of real data from the [Million Song Dataset](https://labrosa.ee.columbia.edu/millionsong/). The files are partitioned by the first three letters of each song's track ID. 

* The log dataset consists of log files in JSON format generated by [this event simulator](https://github.com/Interana/eventsim) based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

### Schema Design:

#### Fact Table(s):
* The songplays table stored the records from log_data that was associated with the songplays

#### Dimension Tables(s):
* The users table stored the users for the streaming app
* The song table stored the songs from the app
* The artists table stored the artists from the app
* The time table stored the timestamp records relevant to the songplay

#### ETL Pipeline:
* Must execute 'create_tables.py' to create the database and create the tables
* To load data into the database, execute 'etl.py'
